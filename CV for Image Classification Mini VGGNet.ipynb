{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 600\n",
    "## Importing a local version of input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "JPEG\n",
      "RGB\n",
      "(224, 224)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(301056,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import warnings\n",
    "\n",
    "# load the image\n",
    "img = load_img(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\train\\\\images\\\\0.jpg\")\n",
    "# report details about the image\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "# show the image\n",
    "img_np = img_to_array(img)\n",
    "img_np.shape\n",
    "img_np = np.expand_dims(img_np, 0)\n",
    "print(img_np.shape)\n",
    "img = load_img(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\train\\\\images\\\\1.jpg\")\n",
    "img_np = np.append(img_np ,img_to_array(img))\n",
    "img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1646, 224, 224, 3) (706, 224, 224, 3) (1646,)\n"
     ]
    }
   ],
   "source": [
    "#filelist = [ str(i)+'.jpg'for i in range(0,2351)]\n",
    "trainX = pd.read_csv(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\train\\\\train.csv\")\n",
    "filelist = trainX['image_names'].values\n",
    "trainY = trainX['emergency_or_not'].values\n",
    "trainX = np.array([np.array(img_to_array(load_img(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\train\\\\images\\\\\"+fname))) for fname in filelist])\n",
    "testX = pd.read_csv(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\test.csv\")\n",
    "filelist = testX['image_names'].values\n",
    "testX = np.array([np.array(img_to_array(load_img(\"D:\\\\Practice\\\\Computer Vision - Vehical Classification\\\\train\\\\images\\\\\"+fname))) for fname in filelist])\n",
    "print(trainX.shape,testX.shape,trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "class MiniVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "        # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1646, 224, 224, 3) (706, 224, 224, 3) (1646, 1)\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "## from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 7\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "trainY = trainY.reshape(-1,1)\n",
    "print(trainX.shape, testX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "# trainX = trainX.astype(\"float32\") / 255.0\n",
    "# testX = testX.astype(\"float32\") / 255.0\n",
    "# one-hot encode the training and testing labels\n",
    " x= np_utils.to_categorical(trainY, 2)\n",
    "# testY = np_utils.to_categorical(testY, 10)\n",
    "# initialize the label names\n",
    "# labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "No File Found\n",
      "I should be skipping if I already have a model for this ... \n",
      "Train on 1646 samples, validate on 1646 samples\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 361s 220ms/step - loss: 0.8523 - accuracy: 0.6665 - val_loss: 11.9621 - val_accuracy: 0.5863\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 364s 221ms/step - loss: 0.5938 - accuracy: 0.7776 - val_loss: 22.4028 - val_accuracy: 0.5930\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 358s 217ms/step - loss: 0.6197 - accuracy: 0.8074 - val_loss: 1.9661 - val_accuracy: 0.6537\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 366s 222ms/step - loss: 0.4070 - accuracy: 0.8597 - val_loss: 0.3403 - val_accuracy: 0.8937\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 355s 215ms/step - loss: 0.3426 - accuracy: 0.8852 - val_loss: 0.1263 - val_accuracy: 0.9435\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 361s 220ms/step - loss: 0.2467 - accuracy: 0.9058 - val_loss: 0.1594 - val_accuracy: 0.9423\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 374s 227ms/step - loss: 0.1720 - accuracy: 0.9423 - val_loss: 0.0524 - val_accuracy: 0.9824\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 358s 217ms/step - loss: 0.1091 - accuracy: 0.9587 - val_loss: 0.0500 - val_accuracy: 0.9860\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 335s 204ms/step - loss: 0.1142 - accuracy: 0.9617 - val_loss: 0.0318 - val_accuracy: 0.9903\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 328s 199ms/step - loss: 0.1134 - accuracy: 0.9648 - val_loss: 0.0781 - val_accuracy: 0.9891\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 327s 199ms/step - loss: 0.1273 - accuracy: 0.9587 - val_loss: 0.1285 - val_accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 345s 210ms/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.0223 - val_accuracy: 0.9939\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 367s 223ms/step - loss: 0.0745 - accuracy: 0.9727 - val_loss: 0.0139 - val_accuracy: 0.9951\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 377s 229ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.0203 - val_accuracy: 0.9951\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 367s 223ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 0.0267 - val_accuracy: 0.9915\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 363s 220ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0172 - val_accuracy: 0.9951\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 363s 221ms/step - loss: 0.0817 - accuracy: 0.9824 - val_loss: 0.0089 - val_accuracy: 0.9964\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 358s 218ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0201 - val_accuracy: 0.9927\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 368s 224ms/step - loss: 0.0931 - accuracy: 0.9727 - val_loss: 5.5327 - val_accuracy: 0.5881\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 341s 207ms/step - loss: 0.1212 - accuracy: 0.9563 - val_loss: 0.0774 - val_accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=224, height=224, depth=3, classes=2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "# load model\n",
    "from keras.models import load_model\n",
    "model_name = \"model_\"+str(NUM_EPOCHS)+\".h5\"\n",
    "try :\n",
    "    model = load_model(model_name)\n",
    "\n",
    "except :\n",
    "    print(\"No File Found\")\n",
    "created_new_model = False\n",
    "\n",
    "if(model.name != model_name):\n",
    "    created_new_model = True\n",
    "    print(\"I should be skipping if I already have a model for this ... \")\n",
    "    H = model.fit(trainX, trainY,validation_data=(trainX, trainY),batch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved new model and History\n"
     ]
    }
   ],
   "source": [
    "if(created_new_model):\n",
    "    # save model and architecture to single file\n",
    "    model_name = \"model_\"+str(NUM_EPOCHS)+\".h5\"\n",
    "    model.name = model_name\n",
    "    model.save(model_name)\n",
    "    print(\"Saved model to disk\")\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(H.history) \n",
    "\n",
    "   # or save to csv: \n",
    "    hist_csv_file = 'history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    print(\"Saved new model and History\")\n",
    "        \n",
    "if(not created_new_model) :\n",
    "    hist_df = pd.read_csv('history.csv')\n",
    "    H.history = hist_df.to_dict()\n",
    "    print(\"Loaded History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created results\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(testX)\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit.emergency_or_not = pd.Series(y_pred)\n",
    "submit.head()\n",
    "submit.to_csv(\"results.csv\",index=False)\n",
    "print(\"Successfully created results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0ed8f89d0581>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# show a nicely formatted classification report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] evaluating network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n\u001b[0m\u001b[0;32m      7\u001b[0m \ttarget_names=labelNames))\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# plot the training loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testY' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9949861e-01, 5.0136726e-04],\n",
       "       [7.0315524e-05, 9.9992967e-01],\n",
       "       [9.9999917e-01, 8.0075023e-07],\n",
       "       ...,\n",
       "       [4.2030779e-06, 9.9999583e-01],\n",
       "       [9.9990427e-01, 9.5689815e-05],\n",
       "       [9.9997902e-01, 2.0953301e-05]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(testX)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.999, 0.001],\n",
       "       [0.000, 1.000],\n",
       "       [1.000, 0.000],\n",
       "       ...,\n",
       "       [0.000, 1.000],\n",
       "       [1.000, 0.000],\n",
       "       [1.000, 0.000]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "type(y_pred_prob)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000, 1.000],\n",
       "       [1.000, 0.000],\n",
       "       [0.003, 0.997]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
